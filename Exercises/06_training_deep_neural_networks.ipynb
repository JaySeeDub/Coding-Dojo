{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaySeeDub/Coding-Dojo/blob/main/Exercises/06_training_deep_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuiK1GbXVeWQ"
      },
      "source": [
        "# Training Deep Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vum1ecMSVeWU"
      },
      "source": [
        "File name convention: For group 42 and memebers Richard Stallman and Linus <br> Torvalds it would be <br>\n",
        "\"06_Goup42_Stallman_Torvalds.pdf\".\n",
        "\n",
        "Submission via blackboard (UA).\n",
        "\n",
        "Feel free to answer free text questions in text cells using markdown and <br>\n",
        "possibly $\\LaTeX{}$ if you want to.\n",
        "\n",
        "**You don't have to understand every line of code here and it is not intended** <br> **for you to try to understand every line of code.**<br>\n",
        "**Big blocks of code are usually meant to just be clicked through.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdHpNoudVeWU"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gzQlcbcGVeWV"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "import torch\n",
        "assert torch.__version__ >= \"2.0\"\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import keras\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdfX0dKQVeWV"
      },
      "source": [
        "# Vanishing/Exploding Gradients Problem\n",
        "\n",
        "Just like with SGD for linear regression, the fundamental procedure in simple <br>\n",
        "neural networks is to **update model weights and biases** by taking some form of <br>\n",
        "**partial derivative of a loss function** with respect to our weights and biases <br>\n",
        "and then **stepping our weights** in the direction of the negative partial <br>\n",
        "derivative.\n",
        "\n",
        "By **chain rule**, that means that we'll also need to have some kind of <br>\n",
        "**partial derivative of our activation function** with respect to our weights and <br>\n",
        "biases. If the **slope of an activation function** has a tendency to **explode** or <br>\n",
        "**vanish**, then our gradient might also explode or vanish which means we end up <br>\n",
        "taking **steps in our weights** that are **too large** or **too small**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyCN-ihMVeWW"
      },
      "source": [
        "### TASK 1: Sigmoid, Relu, Leaky Relu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "dyKgfaBkVeWW"
      },
      "outputs": [],
      "source": [
        "def logit(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "xsIoTdwPVeWW",
        "outputId": "5b111c8c-9a5c-4094-c53f-a14242ac856f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "z = np.linspace(-5, 5, 200)\n",
        "\n",
        "plt.plot([-5, 5], [0, 0], 'k-')\n",
        "plt.plot([-5, 5], [1, 1], 'k--')\n",
        "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
        "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
        "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
        "props = dict(facecolor='black', shrink=0.1)\n",
        "plt.annotate('', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "plt.annotate('', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "plt.annotate('', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "plt.grid(True)\n",
        "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
        "plt.axis([-5, 5, -0.2, 1.2])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPSnzzKbVeWX"
      },
      "source": [
        "**Task 1 a)** Describe the sigmoid activation function in the three indicated <br>\n",
        "regions in the above plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsnymzLuLvm2"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T052eRDZVeWY"
      },
      "source": [
        "Task 1 a) answer:\n",
        "\n",
        "The slope of the sigmoid is near zero at either end and 0.25 at the middle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0N2ZDw4VeWY"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHJ6UnjCVeWY"
      },
      "source": [
        "### Leaky ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts2lixZlVeWY"
      },
      "source": [
        "**Task 1 b)** Write the [leaky relu](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Leaky_ReLU) function as `def leaky_relu():`. <br>\n",
        "It should take `z` as argument and also another optional argument `alpha` with <br> default value 0.01.<br>\n",
        "The leaky relu function is defined to be `alpha*z` for z<0 and `z` for z>0.\n",
        "\n",
        "(alterntively you can think about using `np.maximum` to make the distinction, <br> assuming alpha>0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKQvZ-g7VeWZ"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "rWjs1EbxVeWZ"
      },
      "outputs": [],
      "source": [
        "def leaky_relu(z, alpha=0.01):\n",
        "  return np.where(z > 0, z, alpha*z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kI_1uaQVeWZ"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Cfbe5XLRVeWZ",
        "outputId": "b943a8af-114b-4020-f123-590e229fa9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
        "plt.plot([-5, 5], [0, 0], 'k-')\n",
        "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
        "plt.grid(True)\n",
        "props = dict(facecolor='black', shrink=0.1)\n",
        "plt.annotate('', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
        "plt.axis([-5, 5, -0.5, 4.2])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwjJDDzBVeWa"
      },
      "source": [
        "**Task 1c)** Describe the difference between relu and leaky relu?\n",
        "Also explain why one might want to use leaky relu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ts4OTJfVeWa"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIeB0L14VeWa"
      },
      "source": [
        "Task 1c) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4en01z7DVeWa"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QWkxwBxVeWa"
      },
      "source": [
        "##### Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zBvPyXLVeWb"
      },
      "outputs": [],
      "source": [
        "# load fashion MNIST + train_test split\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRIUnQUAEsNW"
      },
      "outputs": [],
      "source": [
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X.copy()).float()\n",
        "        self.y = torch.from_numpy(y.copy()).long()\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tp-feDfY-14P"
      },
      "outputs": [],
      "source": [
        "train_data = ClassificationDataset(X_train, y_train)\n",
        "valid_data = ClassificationDataset(X_valid, y_valid)\n",
        "test_data = ClassificationDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "valid_loader = DataLoader(valid_data, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ4zQYliVeWb"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28*28, 300),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(300, 100),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(100, 10),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(train_loader, val_loader, model, optimizer, criterion, num_epochs, metric):\n",
        "    history = {\n",
        "        'epoch': [],\n",
        "        'train_loss': [],\n",
        "        'train_metric': [],\n",
        "        'val_loss': [],\n",
        "        'val_metric': []\n",
        "    }  # Initialize a dictionary to store epoch-wise results\n",
        "\n",
        "    with torch.no_grad():\n",
        "        proper_dtype = torch.int64\n",
        "        X,y = next(iter(train_loader))\n",
        "        try:\n",
        "            loss = criterion(model(X), y.to(proper_dtype))\n",
        "        except:\n",
        "            try:\n",
        "                proper_dtype = torch.float32\n",
        "                loss = criterion(model(X), y.to(proper_dtype))\n",
        "            except:\n",
        "                print(\"No valid data-type could be found\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        epoch_loss = 0.0  # Initialize the epoch loss and metric values\n",
        "        epoch_metric = 0.0\n",
        "\n",
        "        # Training loop\n",
        "        for X, y in train_loader:\n",
        "            y = y.to(proper_dtype)\n",
        "            optimizer.zero_grad()  # Clear existing gradients\n",
        "            outputs = model(X)  # Make predictions\n",
        "            loss = criterion(outputs, y)  # Compute the loss\n",
        "            loss.backward()  # Compute gradients\n",
        "            optimizer.step()  # Update model parameters\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_metric += metric(outputs, y)\n",
        "\n",
        "        # Average training loss and metric\n",
        "        epoch_loss /= len(train_loader)\n",
        "        epoch_metric /= len(train_loader)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        with torch.no_grad():  # Disable gradient calculation\n",
        "            val_loss = 0.0\n",
        "            val_metric = 0.0\n",
        "            for X_val, y_val in val_loader:\n",
        "                y_val = y_val.to(proper_dtype)\n",
        "                outputs_val = model(X_val)  # Make predictions\n",
        "                val_loss += criterion(outputs_val, y_val).item()  # Compute loss\n",
        "                val_metric += metric(outputs_val, y_val)\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            val_metric /= len(val_loader)\n",
        "\n",
        "        # Append epoch results to history\n",
        "        history['epoch'].append(epoch)\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_metric'].append(epoch_metric)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_metric'].append(val_metric)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, '\n",
        "              f'Train Metric: {epoch_metric:.4f}, Val Loss: {val_loss:.4f}, '\n",
        "              f'Val Metric: {val_metric:.4f}')\n",
        "\n",
        "    return history, model"
      ],
      "metadata": {
        "id": "F-yIIV-TIWDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "def accuracy_metric(pred, target):\n",
        "    if len(pred.shape) == 1:\n",
        "        accuracy = torch.sum(torch.eq(pred > 0.5, target)).item() / len(pred)\n",
        "    else:\n",
        "        pred = pred.argmax(dim=1)\n",
        "        accuracy = torch.sum(pred == target).item() / len(pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "Rvl9z0UwIyrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "I6BRfaxwVeWb"
      },
      "outputs": [],
      "source": [
        "history, model = train_and_validate(train_loader, valid_loader, model,\n",
        "                                    optimizer=optimizer, criterion=criterion,\n",
        "                                    num_epochs=10, metric=accuracy_metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhvk8AW7VeWc"
      },
      "source": [
        "### TASK 2: ELU\n",
        "**Task 2 a)** Describe the [ELU activation](https://paperswithcode.com/method/elu) function and compare to LeakyRelu. <br>\n",
        "The definition is described in Chapter 11 or alternatively at the above link."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8Bl9-llVeWc"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnONz5vdVeWc"
      },
      "source": [
        "Task 2 a) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v0A0WekVeWc"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZAMtpWaVeWc"
      },
      "source": [
        "**Task 2 b)** Similar to `leaky_relu` above, write the function `def elu():` as <br> a function of z with optional argument `alpha=1` (meaning that the default <br> value is 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cifsW9jUVeWc"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iGUTv-dVeWc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLxWALLoVeWc"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPN7OA3YVeWd"
      },
      "outputs": [],
      "source": [
        "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
        "plt.plot([-5, 5], [0, 0], 'k-')\n",
        "plt.plot([-5, 5], [-1, -1], 'k--')\n",
        "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
        "plt.grid(True)\n",
        "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
        "plt.annotate('', xytext=(-3.5, 0), xy=(-4, -1), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "plt.axis([-5, 5, -2.2, 3.2])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_zX1ZGRVeWd"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnCxOIWmVeWd"
      },
      "source": [
        "To use the elu activation function in TensorFlow you need to specify the <Br> activation function when building each layer (Check on the [Pytorch Website](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
        "<br>\n",
        "for some examples): <br>\n",
        "`nn.ELU()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLXw3RvHVeWd"
      },
      "source": [
        "**Task 2 c)** Using the same layer dimensions from the previous model <br> (LeakyRelu), train with ELU activation instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFprgEuGVeWd"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu4Vt8JHVeWd"
      },
      "outputs": [],
      "source": [
        "# model = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPVhUUhfVeWe"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "def accuracy_metric(pred, target):\n",
        "    if len(pred.shape) == 1:\n",
        "        accuracy = torch.sum(torch.eq(pred > 0.5, target)).item() / len(pred)\n",
        "    else:\n",
        "        pred = pred.argmax(dim=1)\n",
        "        accuracy = torch.sum(pred == target).item() / len(pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "taUzyXnVKEku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2J3P6NvVeWe"
      },
      "outputs": [],
      "source": [
        "history, model = train_and_validate(train_loader, valid_loader, model,\n",
        "                                    optimizer=optimizer, criterion=criterion,\n",
        "                                    num_epochs=1, metric=accuracy_metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Umd-Y5OVeWe"
      },
      "source": [
        "## Task 3: Batch Normalization\n",
        "**Task 3 a)** Build a NN with two hidden layers with 300 and 100 nodes. Use <br>\n",
        "RELU as activation function. Add [Batch Normalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) layers before each <br>\n",
        "dense layer (check the definition in Chapter 11)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwg8HPGaVeWe"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG3v0q-TVeWe"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    # ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
        "\n",
        "    # ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑\n",
        "    nn.Linear(10),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIdD7ftLVeWe"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "def accuracy_metric(pred, target):\n",
        "    if len(pred.shape) == 1:\n",
        "        accuracy = torch.sum(torch.eq(pred > 0.5, target)).item() / len(pred)\n",
        "    else:\n",
        "        pred = pred.argmax(dim=1)\n",
        "        accuracy = torch.sum(pred == target).item() / len(pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "kj0LojW8MWqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrPLDvNCMWqV"
      },
      "outputs": [],
      "source": [
        "history, model = train_and_validate(train_loader, valid_loader, model,\n",
        "                                    optimizer=optimizer, criterion=criterion,\n",
        "                                    num_epochs=25, metric=accuracy_metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM2u6jcUVeWf"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsRzlilQVeWf"
      },
      "source": [
        "**Task 3 b)** Explain what batch normalization does and discuss the results of above training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zT7x27pVeWf"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ-s9RlzVeWf"
      },
      "source": [
        "Task 3b) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIPTBuROVeWf"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljBkMeqGVeWg"
      },
      "source": [
        "## Task 4: Reusing a Pytorch model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rbAMSSiVeWg"
      },
      "source": [
        "Let's split the fashion MNIST training set in two: <br>\n",
        "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).<br>\n",
        "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
        "\n",
        "The validation set and the test set are also split this way, but without <br>\n",
        "restricting the number of images.\n",
        "\n",
        "**We will train a model on set A (classification task with 8 classes), and try to** <br>\n",
        "**reuse it to tackle set B (binary classification).** We hope to transfer a little <br>\n",
        "bit of knowledge from task A to task B, since classes in set A (sneakers, <br>\n",
        "ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B <br>\n",
        "(sandals and shirts). However, **since we are using `Dense` layers, only patterns** <br>\n",
        "**that occur at the same location can be reused** (in contrast, **convolutional <br> layers will transfer much better**, since learned patterns can be detected <br>\n",
        "anywhere on the image, as we will see in the CNN chapter)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PxxBOgTVeWg"
      },
      "outputs": [],
      "source": [
        "def split_dataset(X, y):\n",
        "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
        "    y_A = y[~y_5_or_6]\n",
        "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
        "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
        "    return ((X[~y_5_or_6], y_A),\n",
        "            (X[y_5_or_6], y_B))\n",
        "\n",
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "X_train_B = X_train_B[:200]\n",
        "y_train_B = y_train_B[:200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD33Y825M-AB"
      },
      "outputs": [],
      "source": [
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X.copy()).float()\n",
        "        self.y = torch.from_numpy(y.copy()).long()\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8mwr0wdM-AB"
      },
      "outputs": [],
      "source": [
        "train_data = ClassificationDataset(X_train_A, y_train_A)\n",
        "valid_data = ClassificationDataset(X_valid_A, y_valid_A)\n",
        "test_data = ClassificationDataset(X_test_A, y_test_A)\n",
        "\n",
        "train_loader_A = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader_A = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "valid_loader_A = DataLoader(valid_data, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ClassificationDataset(X_train_B, y_train_B)\n",
        "valid_data = ClassificationDataset(X_valid_B, y_valid_B)\n",
        "test_data = ClassificationDataset(X_test_B, y_test_B)\n",
        "\n",
        "train_loader_B = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader_B = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "valid_loader_B = DataLoader(valid_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "taLm_R1NNVK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7mQaRIwVeWg"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_A = nn.Sequential()\n",
        "model_A.append(nn.Flatten())\n",
        "n_last = 28*28\n",
        "for n_hidden in (300, 100, 50, 50, 50):\n",
        "    model_A.append(nn.Linear(n_last, n_hidden))\n",
        "    model_A.append(nn.SELU())\n",
        "    n_last = n_hidden\n",
        "model_A.append(nn.Linear(n_last, 8))"
      ],
      "metadata": {
        "id": "6MDH-AAHmPMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_A = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_A.parameters(), lr=0.001)\n",
        "\n",
        "def accuracy_metric(pred, target):\n",
        "    if len(pred.shape) == 1:\n",
        "        accuracy = torch.sum(torch.eq(pred > 0.5, target)).item() / len(pred)\n",
        "    else:\n",
        "        pred = pred.argmax(dim=1)\n",
        "        accuracy = torch.sum(pred == target).item() / len(pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "KPh95jeoOct0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_A, model_A = train_and_validate(train_loader_A, valid_loader_A, model_A,\n",
        "                                        optimizer=optimizer, criterion=criterion_A,\n",
        "                                        num_epochs=30, metric=accuracy_metric)"
      ],
      "metadata": {
        "id": "DP3zvLKKmFnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqBpiXkzVeWh"
      },
      "outputs": [],
      "source": [
        "model_B = nn.Sequential()\n",
        "model_B.append(nn.Flatten())\n",
        "n_last = 28*28\n",
        "for n_hidden in (300, 100, 50, 50, 50):\n",
        "    model_B.append(nn.Linear(n_last, n_hidden))\n",
        "    model_B.append(nn.SELU())\n",
        "    n_last = n_hidden\n",
        "model_B.append(nn.Linear(n_last, 1))\n",
        "model_B.append(nn.Sigmoid())\n",
        "model_B.append(nn.Flatten(start_dim=0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_B = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model_B.parameters(), lr=0.001)\n",
        "\n",
        "def accuracy_metric(pred, target):\n",
        "    if len(pred.shape) == 1:\n",
        "        accuracy = torch.sum(torch.eq(pred > 0.5, target)).item() / len(pred)\n",
        "    else:\n",
        "        pred = pred.argmax(dim=1)\n",
        "        accuracy = torch.sum(pred == target).item() / len(pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "GDPuuWK9OnPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_B, model_B = train_and_validate(train_loader_B, valid_loader_B, model_B,\n",
        "                                        optimizer=optimizer, criterion=criterion_B,\n",
        "                                        num_epochs=30, metric=accuracy_metric)"
      ],
      "metadata": {
        "id": "9NQWNQzBmKlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ib7b4_-GVeWi"
      },
      "outputs": [],
      "source": [
        "model_B_on_A = nn.Sequential()\n",
        "for module in list(model_A.modules())[1:]:\n",
        "    model_B_on_A.append(module)\n",
        "model_B_on_A.append(nn.Linear(8, 1))\n",
        "model_B_on_A.append(nn.Sigmoid())\n",
        "model_B_on_A.append(nn.Flatten(start_dim=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJNpOrlFVeWi"
      },
      "source": [
        "Note that `model_B_on_A` and `model_A` actually share layers now, so **when we** <br>\n",
        "**train one, it will update both models**. If we want **to avoid that**, we need to <br>\n",
        "**build `model_B_on_A` on top of a clone of `model_A`**:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "jRxMirtTtTVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w92mBnQyVeWi"
      },
      "outputs": [],
      "source": [
        "model_A_clone = copy.deepcopy(model_A)\n",
        "model_A_clone.load_state_dict(model_A.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3lWiVpVeWi"
      },
      "outputs": [],
      "source": [
        "for param in model_B_on_A.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model_B_on_A.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "53x5-l_NvYwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtemagkpVeWi"
      },
      "outputs": [],
      "source": [
        "for param in model_B_on_A.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "history_B_on_A, model_B_on_A = train_and_validate(train_loader_B, valid_loader_B, model_B_on_A,\n",
        "                                                  optimizer=optimizer, criterion=criterion_B,\n",
        "                                                  num_epochs=30, metric=accuracy_metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh6BZtgAVeWi"
      },
      "source": [
        "Task 4:\n",
        "a) Evaluate the loss and accuracy of the two models `model_B` and <br> `model_B_on_A` on the sandals/shirts dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, data_loader, criterion, metric=None):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    total_loss = 0.0  # Initialize the total loss and metric values\n",
        "    total_metric = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        proper_dtype = torch.int64\n",
        "        X,y = next(iter(train_loader))\n",
        "        try:\n",
        "            loss = criterion(model(X), y.to(proper_dtype))\n",
        "        except:\n",
        "            try:\n",
        "                proper_dtype = torch.float32\n",
        "                loss = criterion(model(X), y.to(proper_dtype))\n",
        "            except:\n",
        "                print(\"No valid data-type could be found\")\n",
        "\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient tracking\n",
        "        for batch in data_loader:\n",
        "            X, y = batch\n",
        "            y = y.to(proper_dtype)\n",
        "            # Pass the data to the model and make predictions\n",
        "            outputs = model(X)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "            # Add the loss and metric for the batch to the total values\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # THESE LINES HAVE BEEN UPDATED TO ACCOUNT FOR DEFAULT ARGUMENTS\n",
        "            if metric is not None:\n",
        "                total_metric += metric(outputs, y)\n",
        "            else:\n",
        "                total_metric += 0.0\n",
        "\n",
        "    # Average loss and metric for the entire dataset\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    avg_metric = total_metric / len(data_loader)\n",
        "\n",
        "    print(f'Test Loss: {avg_loss:.4f}, Test Metric: {avg_metric:.4f}')\n",
        "\n",
        "    return avg_loss, avg_metric"
      ],
      "metadata": {
        "id": "lKJ58TH0Wtwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEZrJp3sVeWi"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vIaevS74lxUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdPKnttrVeWj"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv2-L0hNVeWj"
      },
      "source": [
        "b) In your own words, explain above \"transfer learning\". Did it help?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON0vOBS7VeWj"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSu8C8TcVeWj"
      },
      "source": [
        "Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkXd9M3lVeWj"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWG9imbQVeWj"
      },
      "source": [
        "## Task 5: Learning Rate Scheduling\n",
        "\n",
        "Just like when we learned about SGD for linear regression, **decreasing the** <br>\n",
        "**learning rate over time can improve convergence**. One way to do this is to write <br>\n",
        "a schedule to decay the learning rate as a function of epoch number.\n",
        "\n",
        "Let's add a an exponential decay of the learning rate:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZPLs_cVVeWj"
      },
      "source": [
        "We will use the following learning rate schedule (exponential):   \n",
        "$ lr = lr_0 \\cdot 0.1 ^ {epoch / 20}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drf86URsVeWk"
      },
      "outputs": [],
      "source": [
        "def exponential_decay(lr0, s):\n",
        "    def exponential_decay_fn(epoch):\n",
        "        return lr0 * 0.1**(epoch / s)\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssGWOMHMVeWl"
      },
      "source": [
        "**Note: If you want to use learning rate decay, it is probably better to use a** <br>\n",
        "**Pytorch built-in function like [ExponentialLR](hhttps://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR) and not program it yourself.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to make our training loop more flexible, we'll add **default values** of <br>\n",
        "`None` for the **metric** and **scheduler**. Depending on the task, we might not <br>\n",
        "always need or want to use a metric or scheduler but this will be our new <br>\n",
        "train and validation loop. We've also added **learning rate tracking** to our <br>\n",
        "model history output."
      ],
      "metadata": {
        "id": "sana55-QUyIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(train_loader, val_loader, model, optimizer, criterion, num_epochs, metric=None, scheduler=None):\n",
        "    history = {\n",
        "        'epoch': [],\n",
        "        'train_loss': [],\n",
        "        'train_metric': [],\n",
        "        'val_loss': [],\n",
        "        'val_metric': [],\n",
        "        'learning_rate': []\n",
        "    }  # Initialize a dictionary to store epoch-wise results\n",
        "\n",
        "    with torch.no_grad():\n",
        "        proper_dtype = torch.int64\n",
        "        X,y = next(iter(train_loader))\n",
        "        try:\n",
        "            loss = criterion(model(X), y.to(proper_dtype))\n",
        "        except:\n",
        "            try:\n",
        "                proper_dtype = torch.float32\n",
        "                loss = criterion(model(X), y.to(proper_dtype))\n",
        "            except:\n",
        "                print(\"No valid data-type could be found\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        epoch_loss = 0.0  # Initialize the epoch loss and metric values\n",
        "        epoch_metric = 0.0\n",
        "\n",
        "        # Training loop\n",
        "        for X, y in train_loader:\n",
        "            y = y.to(proper_dtype)\n",
        "            optimizer.zero_grad()  # Clear existing gradients\n",
        "            outputs = model(X)  # Make predictions\n",
        "            loss = criterion(outputs, y)  # Compute the loss\n",
        "            loss.backward()  # Compute gradients\n",
        "            optimizer.step()  # Update model parameters\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # THESE LINES HAVE BEEN UPDATED TO ACCOUNT FOR DEFAULT ARGUMENTS\n",
        "            if metric is not None:\n",
        "                epoch_metric += metric(outputs, y)\n",
        "            else:\n",
        "                epoch_metric += 0.0\n",
        "\n",
        "        # Average training loss and metric\n",
        "        epoch_loss /= len(train_loader)\n",
        "        epoch_metric /= len(train_loader)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        with torch.no_grad():  # Disable gradient calculation\n",
        "            val_loss = 0.0\n",
        "            val_metric = 0.0\n",
        "            for X_val, y_val in val_loader:\n",
        "                y_val = y_val.to(proper_dtype)\n",
        "                outputs_val = model(X_val)  # Make predictions\n",
        "                val_loss += criterion(outputs_val, y_val).item()  # Compute loss\n",
        "                if metric is not None:\n",
        "                    val_metric += metric(outputs_val, y_val)\n",
        "                else:\n",
        "                    val_metric += 0.0\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            val_metric /= len(val_loader)\n",
        "\n",
        "        # Append epoch results to history\n",
        "        history['epoch'].append(epoch)\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_metric'].append(epoch_metric)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_metric'].append(val_metric)\n",
        "        history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, '\n",
        "              f'Train Metric: {epoch_metric:.4f}, Val Loss: {val_loss:.4f}, '\n",
        "              f'Val Metric: {val_metric:.4f}')\n",
        "\n",
        "        # THESE LINES ARE NEW AND ACCOUNT FOR SCHEDULERS\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "    return history, model"
      ],
      "metadata": {
        "id": "jYIAWlq1UTg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz8q_HR8VeWk"
      },
      "source": [
        "**Task 5:**\n",
        "- Build a NN with: two hidden layers with 300 and 100 nodes, add <br>\n",
        "Batch Normalization layers before the linear layers,\n",
        "- Train the model with `nn.CrossEntropyLoss()` as `criterion`, <br> `scheduler` and `optimizer` provided above and `accuracy` as the `metric`, <br>\n",
        "- Fit the model to `train_loader` for 25 epochs. Use `valid_loader` for the <br>\n",
        "validation data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IULt_p0ZVeWk"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qEmrTh-VeWk"
      },
      "outputs": [],
      "source": [
        "#model =\n",
        "\n",
        "#optimizer = torch.optim.NAdam(model.parameters())\n",
        "#scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, exponential_decay_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMAcLEAnVeWk"
      },
      "outputs": [],
      "source": [
        "#history, model ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8t0NsaeVeWk"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check out our model performance with a test loop."
      ],
      "metadata": {
        "id": "dCfV1NjfXovk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, data_loader, criterion, metric=None):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    total_loss = 0.0  # Initialize the total loss and metric values\n",
        "    total_metric = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        proper_dtype = torch.int64\n",
        "        X,y = next(iter(train_loader))\n",
        "        try:\n",
        "            loss = criterion(model(X), y.to(proper_dtype))\n",
        "        except:\n",
        "            try:\n",
        "                proper_dtype = torch.float32\n",
        "                loss = criterion(model(X), y.to(proper_dtype))\n",
        "            except:\n",
        "                print(\"No valid data-type could be found\")\n",
        "\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient tracking\n",
        "        for batch in data_loader:\n",
        "            X, y = batch\n",
        "            y = y.to(proper_dtype)\n",
        "            # Pass the data to the model and make predictions\n",
        "            outputs = model(X)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "            # Add the loss and metric for the batch to the total values\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # THESE LINES HAVE BEEN UPDATED TO ACCOUNT FOR DEFAULT ARGUMENTS\n",
        "            if metric is not None:\n",
        "                total_metric += metric(outputs, y)\n",
        "            else:\n",
        "                total_metric += 0.0\n",
        "\n",
        "    # Average loss and metric for the entire dataset\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    avg_metric = total_metric / len(data_loader)\n",
        "\n",
        "    print(f'Test Loss: {avg_loss:.4f}, Test Metric: {avg_metric:.4f}')\n",
        "\n",
        "    return avg_loss, avg_metric"
      ],
      "metadata": {
        "id": "dRGJO1ITXy9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0jcKWDaVeWk"
      },
      "outputs": [],
      "source": [
        "# note that the model is overfitting a lot. Might want to use dropout\n",
        "# also a CNN will perform much better as we will see next Hands-On\n",
        "print(\"train loss:\", test_model(model, train_loader, nn.CrossEntropyLoss())[0])\n",
        "print(\"test loss:\", test_model(model, test_loader, nn.CrossEntropyLoss())[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR8vzuI6VeWl"
      },
      "outputs": [],
      "source": [
        "# the learning rate is saved in the history under the key 'learning_rate'\n",
        "print(history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15Bzc2EPVeWl"
      },
      "outputs": [],
      "source": [
        "plt.plot(history['epoch'], history[\"learning_rate\"], \"o-\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYgXFT8oVeWl"
      },
      "source": [
        "## Task 6: Performance Scheduling\n",
        "\n",
        "Because **Loss vs. weight spaces are generally not globally convex-up**, it's <br>\n",
        "likely that your model will get stuck in a **local minimum loss**. When that <br>\n",
        "happens, it can mean that your **learning rate is** so **low** that it's unable to push <br>\n",
        "your model weights outside of the local minimum region. We can try to **increase** <br>\n",
        "**the learning rate** in that case **to escape a local minimum**. This is like pushing <br>\n",
        "a ball further up the side of a valley in the hopes that it eventually rolls <br>\n",
        "over a cliff and down into a deeper valley when you get to the top."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8qoflzSVeWl"
      },
      "source": [
        "For performance scheduling, use the `ReduceLROnPlateau` scheduler. Example: <br>\n",
        "if you step the following learning rate scheduler it will step the learning <br>\n",
        "rate by 0.5 whenever the best validation loss does not improve for two <br>\n",
        "consecutive epochs:\n",
        "\n",
        "`scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(factor=0.5, patience=2)`\n",
        "\n",
        "**You will need to update the `scheduler.step()` portion of the  train_and_validate** <br>\n",
        "loop for `ReduceLROnPlateau`. Refer to the example at the bottom of [this page](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html#torch.optim.lr_scheduler.ReduceLROnPlateau). <br>\n",
        "This is due to the fact that this optimizer has a patience argument that will <br>\n",
        "check a certain quantity to decide whether it's time to step.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(train_loader, val_loader, model, optimizer, criterion, num_epochs, metric=None, scheduler=None):\n",
        "    history = {\n",
        "        'epoch': [],\n",
        "        'train_loss': [],\n",
        "        'train_metric': [],\n",
        "        'val_loss': [],\n",
        "        'val_metric': [],\n",
        "        'learning_rate': []\n",
        "    }  # Initialize a dictionary to store epoch-wise results\n",
        "\n",
        "    with torch.no_grad():\n",
        "        proper_dtype = torch.int64\n",
        "        X,y = next(iter(train_loader))\n",
        "        try:\n",
        "            loss = criterion(model(X), y.to(proper_dtype))\n",
        "        except:\n",
        "            try:\n",
        "                proper_dtype = torch.float32\n",
        "                loss = criterion(model(X), y.to(proper_dtype))\n",
        "            except:\n",
        "                print(\"No valid data-type could be found\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        epoch_loss = 0.0  # Initialize the epoch loss and metric values\n",
        "        epoch_metric = 0.0\n",
        "\n",
        "        # Training loop\n",
        "        for X, y in train_loader:\n",
        "            y = y.to(proper_dtype)\n",
        "            optimizer.zero_grad()  # Clear existing gradients\n",
        "            outputs = model(X)  # Make predictions\n",
        "            loss = criterion(outputs, y)  # Compute the loss\n",
        "            loss.backward()  # Compute gradients\n",
        "            optimizer.step()  # Update model parameters\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # THESE LINES HAVE BEEN UPDATED TO ACCOUNT FOR DEFAULT ARGUMENTS\n",
        "            if metric is not None:\n",
        "                epoch_metric += metric(outputs, y)\n",
        "            else:\n",
        "                epoch_metric += 0.0\n",
        "\n",
        "        # Average training loss and metric\n",
        "        epoch_loss /= len(train_loader)\n",
        "        epoch_metric /= len(train_loader)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        with torch.no_grad():  # Disable gradient calculation\n",
        "            val_loss = 0.0\n",
        "            val_metric = 0.0\n",
        "            for X_val, y_val in val_loader:\n",
        "                y_val = y_val.to(proper_dtype)\n",
        "                outputs_val = model(X_val)  # Make predictions\n",
        "                val_loss += criterion(outputs_val, y_val).item()  # Compute loss\n",
        "                if metric is not None:\n",
        "                    val_metric += metric(outputs_val, y_val)\n",
        "                else:\n",
        "                    val_metric += 0.0\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            val_metric /= len(val_loader)\n",
        "\n",
        "        # Append epoch results to history\n",
        "        history['epoch'].append(epoch)\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_metric'].append(epoch_metric)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_metric'].append(val_metric)\n",
        "        history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, '\n",
        "              f'Train Metric: {epoch_metric:.4f}, Val Loss: {val_loss:.4f}, '\n",
        "              f'Val Metric: {val_metric:.4f}')\n",
        "\n",
        "        if scheduler is not None:\n",
        "            # MODIFY THIS LINE TO WORK PROPERLY FOR REDUCELRONPLATEAU\n",
        "            scheduler.step(  # This will crash if you don't fix it\n",
        "\n",
        "    return history, model"
      ],
      "metadata": {
        "id": "_Dc7qJ7rbDjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js5KNR7VVeWm"
      },
      "source": [
        "**Task 6:**   \n",
        "a) Re-use (copy-paste) the NN from Task 5: two hidden layers with 300 and 100 <br>\n",
        "nodes and Batch Normalization layers before the linear layers. But, now use Adam <br> optimizer with a initial lr=0.01 and ReduceLROnPlateau scheduler.<br>\n",
        "b) Compare the results with the previous one (Task 5), <br>\n",
        "c) Comment on the learning rate as a function of epochs using the plot given <br>below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiU1KpNSVeWm"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ndjYwyRVeWm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNA3UETXVeWm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbpIrSdGVeWm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfUNAspYVeWm"
      },
      "outputs": [],
      "source": [
        "plt.plot(history['epoch'], history[\"learning_rate\"], \"bo-\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\", color='b')\n",
        "plt.tick_params('y', colors='b')\n",
        "plt.gca().set_xlim(0, n_epochs - 1)\n",
        "plt.grid(True)\n",
        "\n",
        "ax2 = plt.gca().twinx()\n",
        "ax2.plot(history['epoch'], history[\"val_loss\"], \"r^-\")\n",
        "ax2.set_ylabel('Validation Loss', color='r')\n",
        "ax2.tick_params('y', colors='r')\n",
        "\n",
        "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0AZiqX-VeWm"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ],
      "metadata": {
        "id": "KpAkO6_DcdG8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0IjQd10VeWm"
      },
      "source": [
        "Task 6 c) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fJ2xV06cZ_Q"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NPXtVJLVeWm"
      },
      "source": [
        "## Task 7 Avoiding Overfitting Through Regularization\n",
        "\n",
        "A **dropout layer** essentially **takes all inputs** passed to it and randomly **sets** <br>\n",
        "**some inputs to 0** with a certain rate. One way that models can **overfit** to <br>\n",
        "training data is by essentially *\"memorizing\"* or encoding into its function some <br>\n",
        "**properties that are specific to one data set**.\n",
        "\n",
        "We can help mitigate this by ensuring our data is as **non-homogeneous within** <br>\n",
        "**each sample** (train, val, test) and as **homogeneous across our samples as** <br>\n",
        "**possible**. This isn't always enough as we often end up showing our model the <br>\n",
        "same training data multiple times and **it may learn patterns about the training** <br>\n",
        "**data that don't exist in other data**.\n",
        "\n",
        "By adding dropout, we **decrease the likelihood that it learns** these sorts of <br>\n",
        "**inter-sample patterns by adding random variations** to either the data or the way <br>\n",
        "it handles the same data each time.\n",
        "\n",
        "Our models above all overfit (why?). Let's now tackle this problem using <br> dropout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC8Dypw2VeWn"
      },
      "source": [
        "**Task 7:**   \n",
        "a) Copy the code for the model of Task 6, add a dropout (20% rate) before each <br> hidden layer (https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) <br>\n",
        "b) Compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zc2SbByVeWn"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvOG26esVeWn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPmzlbiFVeWn"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auu3TwOcVeWn"
      },
      "outputs": [],
      "source": [
        "print(\"train loss:\", test_model(model, train_loader, nn.CrossEntropyLoss())[0])\n",
        "print(\"test loss:\", test_model(model, test_loader, nn.CrossEntropyLoss())[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJRBiKG7VeWn"
      },
      "outputs": [],
      "source": [
        "plt.plot(history['epoch'], history[\"learning_rate\"], \"bo-\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\", color='b')\n",
        "plt.tick_params('y', colors='b')\n",
        "plt.gca().set_xlim(0, n_epochs - 1)\n",
        "plt.grid(True)\n",
        "\n",
        "ax2 = plt.gca().twinx()\n",
        "ax2.plot(history['epoch'], history[\"val_loss\"], \"r^-\")\n",
        "ax2.set_ylabel('Validation Loss', color='r')\n",
        "ax2.tick_params('y', colors='r')\n",
        "\n",
        "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsCwAFz9VeWn"
      },
      "source": [
        "# Optional Exercise (Bonus points): Using Callbacks during Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snHWdBwrVeWn"
      },
      "source": [
        "**Task 8:** Add two of the following features to your model training loop:<br>\n",
        "a) Keep track of the model with the best validation loss and return the best <br>\n",
        "model at the end of the traininig loop instead of the last model.<br>\n",
        "b) Stop model training after 5 epochs of loss not impoving <br>\n",
        "c) Add [Tensorboard logging](https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html) for one or more quantities from your model <br> training history\n",
        "\n",
        "You can use the code snippets below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXmUVkCxVeWo"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "XNThGPOkfaLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(train_loader, val_loader, model, optimizer, criterion, num_epochs, metric=None, scheduler=None):\n",
        "    history = {\n",
        "        'epoch': [],\n",
        "        'train_loss': [],\n",
        "        'train_metric': [],\n",
        "        'val_loss': [],\n",
        "        'val_metric': [],\n",
        "        'learning_rate': []\n",
        "    }  # Initialize a dictionary to store epoch-wise results\n",
        "\n",
        "    with torch.no_grad():\n",
        "        proper_dtype = torch.int64\n",
        "        X,y = next(iter(train_loader))\n",
        "        try:\n",
        "            loss = criterion(model(X), y.to(proper_dtype))\n",
        "        except:\n",
        "            try:\n",
        "                proper_dtype = torch.float32\n",
        "                loss = criterion(model(X), y.to(proper_dtype))\n",
        "            except:\n",
        "                print(\"No valid data-type could be found\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        epoch_loss = 0.0  # Initialize the epoch loss and metric values\n",
        "        epoch_metric = 0.0\n",
        "\n",
        "        # Training loop\n",
        "        for X, y in train_loader:\n",
        "            y = y.to(proper_dtype)\n",
        "            optimizer.zero_grad()  # Clear existing gradients\n",
        "            outputs = model(X)  # Make predictions\n",
        "            loss = criterion(outputs, y)  # Compute the loss\n",
        "            loss.backward()  # Compute gradients\n",
        "            optimizer.step()  # Update model parameters\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # THESE LINES HAVE BEEN UPDATED TO ACCOUNT FOR DEFAULT ARGUMENTS\n",
        "            if metric is not None:\n",
        "                epoch_metric += metric(outputs, y)\n",
        "            else:\n",
        "                epoch_metric += 0.0\n",
        "\n",
        "        # Average training loss and metric\n",
        "        epoch_loss /= len(train_loader)\n",
        "        epoch_metric /= len(train_loader)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        with torch.no_grad():  # Disable gradient calculation\n",
        "            val_loss = 0.0\n",
        "            val_metric = 0.0\n",
        "            for X_val, y_val in val_loader:\n",
        "                y_val = y_val.to(proper_dtype)\n",
        "                outputs_val = model(X_val)  # Make predictions\n",
        "                val_loss += criterion(outputs_val, y_val).item()  # Compute loss\n",
        "                if metric is not None:\n",
        "                    val_metric += metric(outputs_val, y_val)\n",
        "                else:\n",
        "                    val_metric += 0.0\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            val_metric /= len(val_loader)\n",
        "\n",
        "        # Append epoch results to history\n",
        "        history['epoch'].append(epoch)\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_metric'].append(epoch_metric)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_metric'].append(val_metric)\n",
        "        history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, '\n",
        "              f'Train Metric: {epoch_metric:.4f}, Val Loss: {val_loss:.4f}, '\n",
        "              f'Val Metric: {val_metric:.4f}')\n",
        "\n",
        "        if scheduler is not None:\n",
        "            # MODIFY THIS LINE TO WORK PROPERLY FOR REDUCELRONPLATEAU\n",
        "            scheduler.step(  # This will crash if you don't fix it\n",
        "\n",
        "    return history, model"
      ],
      "metadata": {
        "id": "JA9ORcrBiBZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hok1kPtOVeWo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n",
        "\n",
        "def accuracy_metric(pred, target):\n",
        "    if len(pred.shape) == 1:\n",
        "        accuracy = torch.sum(torch.eq(pred > 0.5, target)).item() / len(pred)\n",
        "    else:\n",
        "        pred = pred.argmax(dim=1)\n",
        "        accuracy = torch.sum(pred == target).item() / len(pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "Hfgqmx3Cdzkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWrGsa6Zdzkh"
      },
      "outputs": [],
      "source": [
        "history, model = train_and_validate(train_loader, valid_loader, model,\n",
        "                                    optimizer=optimizer, criterion=criterion,\n",
        "                                    num_epochs=50, metric=accuracy_metric)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "writer.flush()"
      ],
      "metadata": {
        "id": "yNNk1GA9ffr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer.close()"
      ],
      "metadata": {
        "id": "7EHu2mLkfk5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./runs --port=6006"
      ],
      "metadata": {
        "id": "232M-anzhqkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c39ZmsuVeWo"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "nav_menu": {
      "height": "360px",
      "width": "416px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}